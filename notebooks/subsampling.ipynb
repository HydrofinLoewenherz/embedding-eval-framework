{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# switch to main dir to fix local imports\n",
    "import os\n",
    "if os.getcwd().endswith(\"notebooks\"):\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "# package imports\n",
    "from dataclasses import asdict\n",
    "from datetime import datetime\n",
    "import time\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import glob\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# local imports\n",
    "from src.evaluator import Evaluator\n",
    "from src.args import Args\n",
    "import src.graphs as graphs\n",
    "\n",
    "# start autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# select device for machine learning\n",
    "device = \"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"using device: {device}\")\n",
    "\n",
    "# settings for plots (seaborn/matplotlib)\n",
    "sns.set_context(\"paper\")\n",
    "sns.set_style(\"darkgrid\", {\"grid.color\": \".8\"})\n",
    "palette = \"Dark2\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-11T12:40:23.294811485Z",
     "start_time": "2023-06-11T12:40:21.908450504Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load dataframe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result = pd.concat((pd.read_csv(f) for f in glob.glob(\"/out/load/*.csv.zip\")), ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test effects of subsampling for GIRG and RJS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# setup experiment arguments\n",
    "args_list = [\n",
    "    Args(\n",
    "        graph_type=\"girg\",\n",
    "        graph_size=graph_size,\n",
    "        subgraph_alpha=0.15,\n",
    "        subgraph_alg=subgraph_alg\n",
    "    )\n",
    "    for graph_size in [500, 1500, 2500]\n",
    "    for subgraph_alg in [\"wrs\", \"rj\"]\n",
    "    for _ in range(5)  # repetitions for representative results\n",
    "]\n",
    "experiment_key = f\"subsampling-girg--{datetime.now().strftime('%d-%m--%H-%M')}\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-11T12:40:23.307856892Z",
     "start_time": "2023-06-11T12:40:23.284130701Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/30 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "39cf0e351c764284b52fd72be6dda448"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 13\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# train the model\u001B[39;00m\n\u001B[1;32m     12\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[0;32m---> 13\u001B[0m \u001B[43mevaluator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptim\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mAdam\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnet\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1e-3\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpbar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[1;32m     16\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     17\u001B[0m end_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# test the model\u001B[39;00m\n",
      "File \u001B[0;32m~/Projects/embedding-eval-framework/src/evaluator.py:198\u001B[0m, in \u001B[0;36mEvaluator.train\u001B[0;34m(self, optimizer, pbar, track)\u001B[0m\n\u001B[1;32m    195\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwriter\u001B[38;5;241m.\u001B[39madd_scalar(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msubgraph_edges\u001B[39m\u001B[38;5;124m'\u001B[39m, subgraph_edges, epoch)\n\u001B[1;32m    197\u001B[0m \u001B[38;5;66;03m# train epoch\u001B[39;00m\n\u001B[0;32m--> 198\u001B[0m fit_loss, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepoch_dataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    199\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwriter\u001B[38;5;241m.\u001B[39madd_scalar(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfit_loss\u001B[39m\u001B[38;5;124m'\u001B[39m, fit_loss, epoch)\n\u001B[1;32m    201\u001B[0m \u001B[38;5;66;03m# evaluate on epoch dataset\u001B[39;00m\n",
      "File \u001B[0;32m~/Projects/embedding-eval-framework/src/evaluator.py:153\u001B[0m, in \u001B[0;36mEvaluator.fit\u001B[0;34m(self, dataloader, optimizer)\u001B[0m\n\u001B[1;32m    151\u001B[0m preds \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    152\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i_batch, (x_train, y_train) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(dataloader):\n\u001B[0;32m--> 153\u001B[0m     \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mzero_grad\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    154\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnet(x_train)  \u001B[38;5;66;03m# if the loss_fn is with logits, don't use sigmoid\u001B[39;00m\n\u001B[1;32m    155\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss_fn(y_pred, y_train\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mfloat())\n",
      "File \u001B[0;32m~/Projects/embedding-eval-framework/venv/lib/python3.10/site-packages/torch/optim/optimizer.py:456\u001B[0m, in \u001B[0;36mOptimizer.zero_grad\u001B[0;34m(self, set_to_none)\u001B[0m\n\u001B[1;32m    454\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m foreach:\n\u001B[1;32m    455\u001B[0m     per_device_and_dtype_grads \u001B[38;5;241m=\u001B[39m defaultdict(\u001B[38;5;28;01mlambda\u001B[39;00m: defaultdict(\u001B[38;5;28mlist\u001B[39m))\n\u001B[0;32m--> 456\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mrecord_function(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_zero_grad_profile_name):\n\u001B[1;32m    457\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m group \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparam_groups:\n\u001B[1;32m    458\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m group[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mparams\u001B[39m\u001B[38;5;124m'\u001B[39m]:\n",
      "File \u001B[0;32m~/Projects/embedding-eval-framework/venv/lib/python3.10/site-packages/torch/autograd/profiler.py:507\u001B[0m, in \u001B[0;36mrecord_function.__exit__\u001B[0;34m(self, exc_type, exc_value, traceback)\u001B[0m\n\u001B[1;32m    505\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mis_scripting():\n\u001B[1;32m    506\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39mDisableTorchFunctionSubclass():\n\u001B[0;32m--> 507\u001B[0m         \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprofiler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_record_function_exit\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_RecordFunction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrecord\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    508\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    509\u001B[0m     torch\u001B[38;5;241m.\u001B[39mops\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39m_record_function_exit(record)\n",
      "File \u001B[0;32m~/Projects/embedding-eval-framework/venv/lib/python3.10/site-packages/torch/_ops.py:287\u001B[0m, in \u001B[0;36mOpOverload.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    286\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 287\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_op\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# generate data\n",
    "result = pd.DataFrame({})\n",
    "for r, args in enumerate(tqdm(args_list)):\n",
    "    graph = graphs.gen_graph(args)\n",
    "    evaluator = Evaluator(\n",
    "        graph=graph,\n",
    "        args=args,\n",
    "        writer_log_dir=f\"runs/{experiment_key}/{args.graph_type}--{args.__hash__()}--{r}\",\n",
    "        device=device\n",
    "    )\n",
    "    # train the model\n",
    "    start_time = time.perf_counter()\n",
    "    evaluator.train(\n",
    "        optimizer=torch.optim.Adam(evaluator.net.parameters(), lr=1e-3),\n",
    "        pbar=False\n",
    "    )\n",
    "    end_time = time.perf_counter()\n",
    "    # test the model\n",
    "    test_loss, test_ap, test_f1, test_threshold = evaluator.test(\n",
    "        epoch=args.epochs\n",
    "    )\n",
    "    result = pd.concat([\n",
    "        result,\n",
    "        pd.Series({\n",
    "            \"run_time\": end_time - start_time,\n",
    "            \"loss\": test_loss,\n",
    "            \"ap\": test_ap,\n",
    "            \"f1\": test_f1,\n",
    "            **asdict(args),\n",
    "        }).to_frame().T\n",
    "    ], ignore_index=True)\n",
    "    # save after every iteration in case the experiment is interrupted\n",
    "    result.to_csv(f\"./out/{experiment_key}.csv.zip\", index=False, compression=dict(method='zip', archive_name=f\"data.csv\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-11T12:43:28.562100258Z",
     "start_time": "2023-06-11T12:41:51.633312513Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plot grid search results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# run time per graph and epoch graph size (line with std)\n",
    "g = sns.relplot(\n",
    "    data=result, kind=\"line\",\n",
    "    hue=\"subgraph_alg\",\n",
    "    x=\"graph_size\",\n",
    "    y=\"run_time\",\n",
    "    errorbar=\"sd\",\n",
    "    palette=palette,\n",
    "    aspect=2,\n",
    ")\n",
    "g.set_axis_labels(\"Graph Size\", \"Runtime [sec]\")\n",
    "g._legend.set_title(\"Subsampling\")\n",
    "g.figure.savefig(\"./out/subsampling_girg_runtime.pdf\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-11T12:40:43.730832334Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# run time per graph and epoch graph size (line with std)\n",
    "g = sns.relplot(\n",
    "    data=result, kind=\"line\",\n",
    "    hue=\"subgraph_alg\",\n",
    "    x=\"graph_size\",\n",
    "    y=\"ap\",\n",
    "    errorbar=\"sd\",\n",
    "    palette=palette,\n",
    "    aspect=2,\n",
    ")\n",
    "g.set_axis_labels(\"Graph Size\", \"Average Precision\")\n",
    "g._legend.set_title(\"Subsampling\")\n",
    "g.figure.savefig(\"./out/subsampling_girg_ap.pdf\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-11T12:40:43.731866339Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
