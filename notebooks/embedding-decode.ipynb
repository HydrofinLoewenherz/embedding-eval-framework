{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Code from [scale embedding-decoder](https://git.scc.kit.edu/scale/research/embedding-decoder) with slight changes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using project root as working dir\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if os.getcwd().endswith(\"notebooks\"):\n",
    "    os.chdir(\"..\")\n",
    "    print(\"using project root as working dir\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "generating random-uniform nodes on disc:   0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fce207a4124d4fb19c5b18728940fbb7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "creating dict from list:   0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "54d229bb41df4febb814e94eac358489"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "generating node pairs:   0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fc3f50613f9d478f9475278ec74a8478"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "generating dataset from node pairs:   0%|          | 0/4950 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "08d398b8db074c6c9245e5dadcad5fb8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model layers\n",
      "compiling model\n",
      "tessst\n",
      "splitting dataset of 4950 values into 3465.0/1485.0\n",
      "len ds 4950\n",
      "len ds 4950\n",
      "train: 3465, test: 1485\n",
      "fitting model\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 4), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (4,).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Paul\\PycharmProjects\\embedding-eval-framework\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Paul\\PycharmProjects\\embedding-eval-framework\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Paul\\PycharmProjects\\embedding-eval-framework\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Paul\\PycharmProjects\\embedding-eval-framework\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\Paul\\PycharmProjects\\embedding-eval-framework\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Paul\\PycharmProjects\\embedding-eval-framework\\venv\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 250, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential' (type Sequential).\n    \n    Input 0 of layer \"dense\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (4,)\n    \n    Call arguments received by layer 'sequential' (type Sequential):\n      • inputs=tf.Tensor(shape=(4,), dtype=float64)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_23004\\1966438029.py\u001B[0m in \u001B[0;36m<cell line: 9>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mepochs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m10\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmain\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\PycharmProjects\\embedding-eval-framework\\src\\main.py\u001B[0m in \u001B[0;36mrun\u001B[1;34m(args)\u001B[0m\n\u001B[0;32m    140\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    141\u001B[0m     \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbuild_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 142\u001B[1;33m     \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrun_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdataset\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    143\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\embedding-eval-framework\\src\\main.py\u001B[0m in \u001B[0;36mrun_model\u001B[1;34m(model, ds, args)\u001B[0m\n\u001B[0;32m    121\u001B[0m     \u001B[1;31m# fit & evaluate\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    122\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'fitting model'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 123\u001B[1;33m     \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mds_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mepochs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    124\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'evaluating model'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    125\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mevaluate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mds_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\embedding-eval-framework\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     68\u001B[0m             \u001B[1;31m# To get the full stack trace, call:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     69\u001B[0m             \u001B[1;31m# `tf.debugging.disable_traceback_filtering()`\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 70\u001B[1;33m             \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     71\u001B[0m         \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     72\u001B[0m             \u001B[1;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\embedding-eval-framework\\venv\\lib\\site-packages\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mtf__train_function\u001B[1;34m(iterator)\u001B[0m\n\u001B[0;32m     13\u001B[0m                 \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m                     \u001B[0mdo_return\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 15\u001B[1;33m                     \u001B[0mretval_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mag__\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconverted_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mag__\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mld\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstep_function\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mag__\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mld\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mag__\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mld\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfscope\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     16\u001B[0m                 \u001B[1;32mexcept\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m                     \u001B[0mdo_return\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: in user code:\n\n    File \"C:\\Users\\Paul\\PycharmProjects\\embedding-eval-framework\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Paul\\PycharmProjects\\embedding-eval-framework\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Paul\\PycharmProjects\\embedding-eval-framework\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Paul\\PycharmProjects\\embedding-eval-framework\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\Paul\\PycharmProjects\\embedding-eval-framework\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Paul\\PycharmProjects\\embedding-eval-framework\\venv\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 250, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential' (type Sequential).\n    \n    Input 0 of layer \"dense\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (4,)\n    \n    Call arguments received by layer 'sequential' (type Sequential):\n      • inputs=tf.Tensor(shape=(4,), dtype=float64)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "import src.main as main\n",
    "\n",
    "args = main.Args()\n",
    "args.graph_size = 100\n",
    "args.batch_size = 10\n",
    "args.rg_radius = 0.2\n",
    "args.epochs = 10\n",
    "\n",
    "result = main.run(args)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Old"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "import tensorflow as tf\n",
    "import networkx as nx\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "import src.main as main\n",
    "\n",
    "from src.map import Map\n",
    "from src.disc import gen_disc_graph, gen_disc_edge"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "args = Map(\n",
    "    batch_size = 64,\n",
    "    epochs = 30,\n",
    "    random_seed = None,\n",
    "    graph_size = 1000,\n",
    "    graph_average_degree = 10,\n",
    "    rg_radius = 0.05,\n",
    "    layers = 10,\n",
    "    layer_size = 16,\n",
    "    train_size = 0.7,\n",
    "    wandb = False,\n",
    "    ds_padded = True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if args.wandb:\n",
    "    wandb.login()\n",
    "    wandb.init(project=\"embedding-eval-framework\", entity=\"hydrofin\")\n",
    "    wandb.run"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Padding:: Result for now: -> No big difference\n",
    "## Padding:: maybe remove non-edges\n",
    "## Padding:: maybe implement into 'tf.data.Dataset.from_tensor_slices' and normalize batches\n",
    "\n",
    "## run multiple times and average (min 10)\n",
    "## preprocess with data padding (duplicate edges in buckets so that all buckets have same amount of edges)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def parse_graph(graph):\n",
    "    graph_nodes = nx.nodes(graph)\n",
    "    # all combinations of x and y (with x > y)\n",
    "    node_pairs = [ [i_p0, i_p1] for i_p0 in tqdm(range(graph.number_of_nodes()), desc=\"generating edge pairs\") for i_p1 in range(i_p0 + 1, graph.number_of_nodes()) ]\n",
    "    ds_values = [ [graph_nodes[ei0]['pos'][0], graph_nodes[ei0]['pos'][1], graph_nodes[ei1]['pos'][0], graph_nodes[ei1]['pos'][1]] for [ei0, ei1] in tqdm(node_pairs, desc=\"mapping edge positions\") ]\n",
    "    ds_labels = [ 1 if graph.has_edge(ei0, ei1) else 0 for [ei0, ei1] in tqdm(node_pairs, desc=\"creating labels for edges\") ]\n",
    "    return node_pairs, ds_values, ds_labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def pad_dataset(ds_values, ds_labels):\n",
    "    label_diff = ds_labels.count(0) - ds_labels.count(1)\n",
    "    label1_is = [i for i, el in tqdm(enumerate(ds_labels), desc=\"generating duplicates\") if el == 1]\n",
    "    label1_is_sample = random.sample(label1_is, label_diff, counts=([label_diff] * len(label1_is)))\n",
    "    pad_values = ds_values + [ds_values[i] for i in tqdm(label1_is_sample, desc=\"adding duplicates for positions\")]\n",
    "    pad_labels = ds_labels + [ds_labels[i] for i in tqdm(label1_is_sample, desc=\"adding duplicates for labels\")]\n",
    "    return pad_values, pad_labels\n",
    "\n",
    "\n",
    "def prepare_dataset(ds_values, ds_labels):\n",
    "    if args.ds_padded:\n",
    "        pad_values, pad_labels = pad_dataset(ds_values, ds_labels)\n",
    "    else:\n",
    "        pad_values, pad_labels = ds_values, ds_labels\n",
    "\n",
    "    n_values = len(pad_values)\n",
    "\n",
    "    full_dataset = tf.data.Dataset\\\n",
    "        .from_tensor_slices((pad_values, pad_labels))\\\n",
    "        .batch(args.batch_size)\\\n",
    "        .shuffle(np.ceil(n_values / 2))\n",
    "    n_train = int(args.train_size * n_values)\n",
    "    train_dataset = full_dataset.take(n_train)\n",
    "    test_dataset = full_dataset.skip(n_train)\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "\n",
    "def run_model(train_dataset, test_dataset):\n",
    "    # build model\n",
    "    model_array = [tf.keras.layers.InputLayer(input_shape=4)]\n",
    "    for i in range(args.layers):\n",
    "        model_array.append(tf.keras.layers.Dense(args.layer_size, activation='relu'))\n",
    "    model_array.append(tf.keras.layers.Flatten())\n",
    "    model_array.append(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    dense_model = tf.keras.Sequential(model_array)\n",
    "    dense_model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),  # TODO try other loss function\n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            tf.keras.metrics.Recall(thresholds=0),\n",
    "            tf.keras.metrics.AUC(\n",
    "                curve=\"PR\"\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    callbacks = []\n",
    "    if args.wandb:\n",
    "        callbacks.append(WandbCallback())\n",
    "    # run model\n",
    "    dense_model.fit(train_dataset, epochs=args.epochs, callbacks=callbacks, verbose=1)\n",
    "    eval_result = list(dense_model.evaluate(test_dataset, verbose=1)) # list(loss, acc, recall, auc) # ERROR\n",
    "    return dense_model, eval_result\n",
    "\n",
    "## iterate over un-padded edges and calculate https://discord.com/channels/934839185855086662/988688735161946144/1070345614782632017\n",
    "## - does the padding change the result?\n",
    "## - weight edges higher than non-edges\n",
    "## - use as loss function and metric\n",
    "\n",
    "## mathematically define the BinaryCrossentropy in this model\n",
    "## - used to compare to fastgae\n",
    "## - compare to other loss functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# run multiple times\n",
    "results = []\n",
    "models = []\n",
    "for iteration in range(1):\n",
    "    print(f'starting iteration {iteration}')\n",
    "    # generate graph\n",
    "    graph, node_positions, _ = gen_disc_graph(args.graph_size, args.graph_average_degree, args.rg_radius)\n",
    "    # create & run model\n",
    "    node_pairs, ds_values, ds_labels = parse_graph(graph)\n",
    "    ds_train, ds_test = prepare_dataset(ds_values, ds_labels)\n",
    "    model, result = run_model(ds_train, ds_test)\n",
    "    results.append(result)\n",
    "    models.append((model, graph, node_positions, node_pairs, ds_values, ds_labels))\n",
    "\n",
    "losses, accs, recalls, aucs = zip(*results)\n",
    "\n",
    "print(f'finished training models')\n",
    "print(f'avg_loss: {np.average(losses)}  std_loss: {np.std(losses)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get best model\n",
    "(model, graph, node_positions, node_pairs, ds_values, ds_labels) = models[(losses.index(min(losses)))]\n",
    "predictions = [pred[0] for pred in model.predict(ds_values)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print best model\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "# print original graph\n",
    "ax[0].set_axis_off()\n",
    "ax[0].set_aspect('equal')\n",
    "ax[0].set_title(\"original graph\")\n",
    "nx.draw_networkx(graph, node_positions, ax=ax[0], node_size=5, with_labels=False, labels={})\n",
    "\n",
    "# generate predict graph\n",
    "threshold = 0.1\n",
    "colors_filtered = np.array([pred for pred in tqdm(predictions, desc=f'generating colors') if pred > threshold])\n",
    "colormap = sns.color_palette(\"flare\", as_cmap=True)\n",
    "pred_graph = nx.Graph()\n",
    "pred_node_pairs = [edge for i, edge in enumerate(node_pairs) if predictions[i] > threshold]\n",
    "pred_graph.add_edges_from(pred_node_pairs)\n",
    "\n",
    "# print predicted graph\n",
    "ax[1].set_axis_off()\n",
    "ax[1].set_aspect('equal')\n",
    "ax[1].set_title(\"reconstructed graph\")\n",
    "nx.draw_networkx(pred_graph, node_positions, ax=ax[1], node_size=5, with_labels=False, labels={}, edge_color=colors_filtered, edge_cmap=colormap)\n",
    "\n",
    "# add color bar for predictions\n",
    "cax = fig.add_axes([ax[1].get_position().x1 + 0.01, ax[1].get_position().y0, 0.02, ax[1].get_position().height])\n",
    "fig.colorbar(mpl.cm.ScalarMappable(cmap=colormap), cax=cax, label=\"confidence\")\n",
    "\n",
    "plt.savefig('./filename.png', dpi=300)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# OLD"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if args.wandb:\n",
    "    wandb.finish()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Additional Plots\n",
    "\n",
    "Additional plots of information about the decoder."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "distances = [math.dist([px, py], [qx, qy]) for [px, py, qx, qy] in ds_edges_pos]\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(distances, edge_prediction, s=0.01)\n",
    "plt.show()\n",
    "## smaller points\n",
    "## also with lines between (has to be sorted first)\n",
    "## plot into #of-edges per distance (see how much data/information the nn gets per distance)\n",
    "## more points (for more information around threshold distance)\n",
    "\n",
    "## get threshold back with ml/wsk-theory"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist2d([dist for dist in distances], edge_prediction, bins=(np.arange(0, 1, 0.01), np.arange(0, 1, 0.01)))\n",
    "ax.set(xlim=(0, 1), ylim=(0, 1))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_distances = np.arange(0, 1, 0.01)\n",
    "dist_dup = 10\n",
    "test_edges = [(d, gen_disc_edge(d)) for d in np.tile(test_distances, dist_dup)]\n",
    "test_edges"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_predictions = dense_model.predict([edge for (_, edge) in test_edges]) # cartesian\n",
    "test_edge_prediction = [pred[0] for pred in test_predictions]\n",
    "len(test_edges), len(test_edge_prediction)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter([d for (d, _) in test_edges], test_edge_prediction)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sorted_dist, sorted_pred = zip(*sorted(zip([d for (d, _) in test_edges], test_edge_prediction), key = lambda x: x[0]))\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(sorted_dist, sorted_pred, marker='o', linewidth=1, markersize=3)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist2d([d for (d, _) in test_edges], test_edge_prediction, bins=(np.arange(0, 1, 0.1), np.arange(0, 1, 0.1)))\n",
    "ax.set(xlim=(0, 1), ylim=(0, 1))\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
