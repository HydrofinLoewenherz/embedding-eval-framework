{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# switch to main dir to fix imports\n",
    "import os\n",
    "\n",
    "if os.getcwd().endswith(\"notebooks\"):\n",
    "    os.chdir(\"..\")\n",
    "    print(\"using project root as working dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from dataclasses import asdict\n",
    "from datetime import datetime\n",
    "import time\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from src.evaluator import Evaluator\n",
    "from src.args import Args\n",
    "import src.graphs as graphs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# start autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# select device\n",
    "device = \"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"using {device} device\")\n",
    "\n",
    "# global seaborn settings\n",
    "sns.set_context(\"paper\")\n",
    "sns.set_style(\"darkgrid\", {\"grid.color\": \".8\"})\n",
    "palette = \"Dark2\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load data frames\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load data frame from folder\n",
    "path = \"./out/load\"\n",
    "files = glob.glob(os.path.join(path, \"*.csv.zip\"))\n",
    "df = pd.concat((pd.read_csv(f) for f in files), ignore_index=True)\n",
    "\n",
    "# either replace or concat\n",
    "result = df\n",
    "#df_result = pd.concat((df_result, df), ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save data frame\n",
    "result.to_csv(os.path.join(path, \"./out/saved.csv.zip\"), index=False, compression=dict(method='zip', archive_name=f\"data.csv\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Run grid search for RJS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1. configure experiment\n",
    "args_list = [\n",
    "    Args(\n",
    "        graph_type=\"girg\",\n",
    "        graph_size=graph_size,\n",
    "        subgraph_size=subgraph_size,\n",
    "        subgraph_alpha=subgraph_alpha\n",
    "    )\n",
    "    for graph_size in [500, 1000, 2500]\n",
    "    for subgraph_size in [50, 100, 250]\n",
    "    for subgraph_alpha in [0.0, 0.05, 0.15, 0.3, 1.0]\n",
    "]\n",
    "experiment_key = f\"gridsearch-girg-rjs--{datetime.now().strftime('%d-%m--%H-%M')}\"\n",
    "repetitions = 5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2. define how to evaluate\n",
    "def evaluate(args: Args, rep: int) -> pd.DataFrame:\n",
    "        graph = graphs.gen_graph(args)\n",
    "        evaluator = Evaluator(\n",
    "            graph=graph,\n",
    "            args=args,\n",
    "            writer_log_dir=f\"runs/{experiment_key}/{args.graph_type}--{args.__hash__()}--{rep}\",\n",
    "            device=device\n",
    "        )\n",
    "        # train the model\n",
    "        start_time = time.perf_counter()\n",
    "        evaluator.train(\n",
    "            optimizer=torch.optim.Adam(evaluator.net.parameters(), lr=1e-3),\n",
    "            pbar=False\n",
    "        )\n",
    "        end_time = time.perf_counter()\n",
    "        # test the model\n",
    "        test_loss, test_ap, test_f1 = evaluator.test(\n",
    "            epoch=args.epochs\n",
    "        )\n",
    "        return pd.DataFrame({\n",
    "            # run meta\n",
    "            \"rep\": rep,\n",
    "            \"run_time\": end_time - start_time,\n",
    "            # run results\n",
    "            \"loss\": test_loss,\n",
    "            \"ap\": test_ap,\n",
    "            \"f1\": test_f1,\n",
    "            # run args\n",
    "            **asdict(args),\n",
    "        })"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 3. run experiment\n",
    "result = pd.DataFrame({})\n",
    "for args, rep in tqdm([\n",
    "    (args, rep)\n",
    "    for args in args_list\n",
    "    for rep in range(repetitions)\n",
    "]):\n",
    "    res = evaluate(args, rep)\n",
    "    result = pd.concat([result, res], ignore_index=True)\n",
    "    result.to_csv(f\"./out/{args.graph_type}--{experiment_key}.csv.zip\", index=False, compression=dict(method='zip', archive_name=f\"data.csv\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plot grid search results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# specify the alpha values to include in the plot\n",
    "alphas = [0.0, 0.15, 1.0] # np.unique([args.subgraph_alpha for args in args_list])\n",
    "\n",
    "figsize = 30\n",
    "fig, axs = plt.subplots(\n",
    "    ncols=len(alphas),\n",
    "    figsize=(figsize, figsize / len(alphas)),\n",
    "    sharey='all'\n",
    ")\n",
    "cbar_ax = axs[len(alphas) - 1].inset_axes([1.04, 0.0, 0.05, 1.0])\n",
    "for i, a in enumerate(alphas):\n",
    "    df_hm = result\\\n",
    "        .loc[result[\"subgraph_alpha\"] == a]\\\n",
    "        .groupby([\"graph_size\", \"subgraph_size\"], as_index=False)[\"ap\"].mean()\n",
    "    g = sns.heatmap(\n",
    "        vmin=0.0,\n",
    "        vmax=1.0,\n",
    "        data=df_hm.pivot(index=\"graph_size\", columns=\"subgraph_size\", values=\"ap\"),\n",
    "        ax=axs[i],\n",
    "        cbar_ax=cbar_ax,\n",
    "        cbar_kws={ \"label\": \"Mean Average Precision\" },\n",
    "        cmap=\"flare\",\n",
    "        square=True\n",
    "    )\n",
    "    axs[i].set_title(f\"Subgraph Alpha = {a}\")\n",
    "    g.set(xlabel=\"Subgraph Size\", ylabel=\"Graph Size\")\n",
    "\n",
    "plt.tight_layout(pad=2)\n",
    "plt.savefig('./out/grid_search.pdf')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
