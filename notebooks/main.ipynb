{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.getcwd().endswith(\"notebooks\"):\n",
    "    os.chdir(\"..\")\n",
    "    print(\"using project root as working dir\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import List, Tuple\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchmetrics.classification import BinaryConfusionMatrix\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "@dataclass\n",
    "class Args:\n",
    "    random_seed = None\n",
    "    # torch\n",
    "    batch_size = 10\n",
    "    epochs = 100\n",
    "    layers = 10\n",
    "    layer_size = 16\n",
    "    train_size = 0.8\n",
    "    wandb = False\n",
    "    # graph\n",
    "    graph_size = 800\n",
    "    graph_shape = 'disc'\n",
    "    rg_radius = 0.05\n",
    "    subsample = \"bfs\"\n",
    "    subsample_size = 100\n",
    "    balance = False\n",
    "\n",
    "    def print(self):\n",
    "        return f\"\"\"\n",
    "            random_seed = {self.random_seed}\n",
    "            # torch\n",
    "            batch_size = {self.batch_size}\n",
    "            epochs = {self.epochs}\n",
    "            layers = {self.layers}\n",
    "            layer_size = {self.layer_size}\n",
    "            train_size = {self.train_size}\n",
    "            wandb = {self.wandb}\n",
    "            # graph\n",
    "            graph_size = {self.graph_size}\n",
    "            graph_shape = {self.graph_shape}\n",
    "            rg_radius = {self.rg_radius}\n",
    "            subsample = {self.subsample}\n",
    "            subsample_size = {self.subsample_size}\n",
    "            balance = {self.balance}\n",
    "        \"\"\"\n",
    "\n",
    "args = Args()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, WeightedRandomSampler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"using {device} device\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NodePosition = Tuple[float, float]\n",
    "NodePositions = List[NodePosition]\n",
    "NodeIndexPairs = List[Tuple[int, int]]\n",
    "\n",
    "def gen_nodes(size: int, shape: str = \"disc\") -> NodePositions:\n",
    "    if shape == 'disc':\n",
    "        return __gen_nodes_disc(size)\n",
    "    else:\n",
    "        raise f'unsupported node shape: {shape}'\n",
    "\n",
    "\n",
    "def __gen_nodes_disc(amount: int) -> NodePositions:\n",
    "    points = []\n",
    "    with tqdm(total=amount, desc=\"generating random-uniform nodes on disc\") as pbar:\n",
    "        while len(points) < amount:\n",
    "            p = (random.uniform(0, 1), random.uniform(0, 1))\n",
    "            d = (p[0] - 0.5, p[1] - 0.5)\n",
    "            if math.sqrt(d[0] * d[0] + d[1] * d[1]) > 0.5:\n",
    "                continue\n",
    "            points.append(p)\n",
    "            pbar.update(1)\n",
    "    return points\n",
    "\n",
    "# generates an edge with a specified distance on a unit disc\n",
    "# the distance has to be in (0, 1).\n",
    "def gen_disc_edge(d: float) -> [float, float, float, float]:\n",
    "    # loop with p in case p is badly chosen\n",
    "    while True:\n",
    "        px, py = random.uniform(0, 1), random.uniform(0, 1)\n",
    "        v = np.random.random(2) # random direction\n",
    "        vd = (v / np.linalg.norm(v)) * d\n",
    "        [qx, qy] = [px, py] + vd\n",
    "        if math.dist([px, py], [0.5, 0.5]) <= 0.5 and math.dist([qx, qy], [0.5, 0.5]) <= 0.5:\n",
    "            return [px, py, qx, qy]\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/a/36460020/10619052\n",
    "def list_to_dict(items: list) -> dict:\n",
    "    return {v: k for v, k in enumerate(items)}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define graph builder\n",
    "class RandomGeometricGraphBuilder:\n",
    "    def __init__(self):\n",
    "        # generate graph\n",
    "        self.nodes = gen_nodes(args.graph_size, args.graph_shape)\n",
    "        self.n_nodes = len(self.nodes)\n",
    "        self.graph = nx.random_geometric_graph(\n",
    "            self.n_nodes,\n",
    "            args.rg_radius,\n",
    "            pos=list_to_dict(self.nodes)\n",
    "        )\n",
    "        self.adjacency_matrix = nx.adjacency_matrix(self.graph)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(4, args.layer_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(args.layer_size, args.layer_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(args.layer_size, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear_relu_stack(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Graph Subsampling\n",
    "\n",
    "Graph subsampling allows the model to train on a smaller set of nodes (and edges).\n",
    "As the model learns based on all node pairs and the number of pairs strongly increases with the number of nodes, subsampling will (in most cases) provide a big speedup.\n",
    "\n",
    "**Technics**\n",
    "- random (sized,ranked)\n",
    "- random walk (sized,ranked,jump)\n",
    "- bfs (sized)\n",
    "- dfs (sized)\n",
    "- forest fire (flammability)\n",
    "\n",
    "**Node Rankings**\n",
    "- uniform\n",
    "- node degree\n",
    "- page rank\n",
    "- sizes of weakly connected components (`wcc`)\n",
    "- sizes of strongly connected components (`scc`)\n",
    "- Hop-plot\n",
    "- Hop-plot on the largest `wcc`\n",
    "- clustering coefficient (`C_d`)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Graph helper class\n",
    "class Graph:\n",
    "    def __init__(self, nodes: NodePositions, adjacency_matrix):\n",
    "        self.nodes = nodes\n",
    "        self.adjacency_matrix = adjacency_matrix\n",
    "        # general pre-calculations\n",
    "        self.n_nodes = len(nodes)\n",
    "        self.node_index_pairs = list(itertools.combinations(range(self.n_nodes), 2))\n",
    "        self.node_degrees = self.adjacency_matrix.sum(axis=0)\n",
    "        # 'random_walk' pre-calculations\n",
    "        self.walk_weights = [\n",
    "            l.todense()[0] if (l := self.node_degrees[i] * self.adjacency_matrix.getrow(i)).sum() > 0 else [1]*self.n_nodes\n",
    "            for i in range(self.n_nodes)\n",
    "        ]\n",
    "\n",
    "    def subgraph(self, alg: str, size: int) -> List[int]:\n",
    "        if alg == \"node_degree\":\n",
    "            return self.node_degree_subgraph(size)\n",
    "        elif alg == \"random_walk\":\n",
    "            return self.random_walk_subgraph(size)\n",
    "        elif alg == \"bfs\":\n",
    "            return self.bfs_subgraph(size)\n",
    "\n",
    "\n",
    "    def node_degree_subgraph(self, size: int, replacement: bool = False):\n",
    "        return list(WeightedRandomSampler(self.node_degrees, size, replacement=replacement))\n",
    "\n",
    "\n",
    "    # TODO add random jumps\n",
    "    def random_walk_subgraph(self, size: int):\n",
    "        def walk(start: int, n: int):\n",
    "            visited = [start]\n",
    "            yield start\n",
    "            curr = start\n",
    "            while len(visited) < n:\n",
    "                curr = random.choices(\n",
    "                    range(self.n_nodes),\n",
    "                    weights=self.walk_weights[curr]\n",
    "                )[0]\n",
    "                if curr in visited:\n",
    "                    continue\n",
    "                visited.append(curr)\n",
    "                yield curr\n",
    "        return list(walk(\n",
    "            random.choices(\n",
    "                range(self.n_nodes),\n",
    "                weights=self.node_degrees\n",
    "            )[0],\n",
    "            size\n",
    "        ))\n",
    "\n",
    "\n",
    "    # TODO add random jumps\n",
    "    def bfs_subgraph(self, size: int):\n",
    "        def bfs(start: int, n: int):\n",
    "            visit = [start]\n",
    "            visited = []\n",
    "            while len(visited) < n:\n",
    "                if len(visit) == 0:\n",
    "                    visit.append(\n",
    "                        random.choice(range(self.n_nodes)))\n",
    "                    print(\"random jump\")\n",
    "                curr = visit.pop(0)\n",
    "                if curr in visited:\n",
    "                    continue\n",
    "                visited.append(curr)\n",
    "                yield curr\n",
    "                visit.extend([\n",
    "                    n\n",
    "                    for n in range(self.n_nodes)\n",
    "                    if self.adjacency_matrix[curr, n] == 1\n",
    "                ])\n",
    "        return list(bfs(\n",
    "            random.choice(\n",
    "                range(self.n_nodes)\n",
    "            ),\n",
    "            size\n",
    "        ))\n",
    "\n",
    "\n",
    "    #? sample: forest fire"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import time\n",
    "graph_builder = RandomGeometricGraphBuilder()\n",
    "graph = Graph(\n",
    "    graph_builder.nodes,\n",
    "    graph_builder.adjacency_matrix,\n",
    ")\n",
    "times = []\n",
    "for _ in range(10):\n",
    "    start_time = time.time()\n",
    "    res = graph.random_walk_subgraph(250)\n",
    "    times.append(time.time() - start_time)\n",
    "print(len(set(res)), np.mean(times))\n",
    "# yield: 0.020 - 0.025"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# Define evaluator\n",
    "class EmbeddingEvaluator:\n",
    "    def __init__(self, graph: Graph):\n",
    "        self.graph = graph\n",
    "        # complete dataset\n",
    "        values = [ e.flatten().tolist() for e in np.array(self.graph.nodes)[self.graph.node_index_pairs]]\n",
    "        labels = [ int(self.graph.adjacency_matrix[s]) for s in self.graph.node_index_pairs ]\n",
    "        self.n_labels = len(labels)\n",
    "        self.n_labels_0 = labels.count(0)\n",
    "        self.ds_values = torch.FloatTensor(values).to(device)\n",
    "        self.ds_labels = torch.FloatTensor(labels).to(device)\n",
    "        self.dataset = TensorDataset(self.ds_values, self.ds_labels)\n",
    "        self.dataloader = DataLoader(self.dataset, batch_size=args.batch_size, shuffle=True)\n",
    "        # generate net\n",
    "        self.net = NeuralNetwork().to(device)\n",
    "        # tensorboard\n",
    "        self.writer = SummaryWriter()\n",
    "\n",
    "    def train(self, loss_fn, optimizer, print_losses: bool = True):\n",
    "        losses = []\n",
    "        self.writer.add_text(\"args\", args.print())\n",
    "\n",
    "        self.net.train()\n",
    "        with tqdm(total=args.epochs, desc=\"training model...\") as pbar:\n",
    "            for epoch in range(args.epochs):\n",
    "                pbar.set_description(f\"epoch {epoch + 1}\")\n",
    "                epoch_loss_sum = 0\n",
    "\n",
    "                # sample subgraph (by node degree) and generate dataset\n",
    "                sampled_nodes = self.graph.subgraph(args.subsample, args.subsample_size)\n",
    "\n",
    "                sampled_node_pairs = list(itertools.combinations(sampled_nodes, 2))\n",
    "                values = [ e.flatten().tolist() for e in np.array(self.graph.nodes)[sampled_node_pairs]]\n",
    "                labels = [ int(self.graph.adjacency_matrix[s]) for s in sampled_node_pairs ]\n",
    "\n",
    "                ds_values = torch.FloatTensor(values).to(device)\n",
    "                ds_labels = torch.FloatTensor(labels).to(device)\n",
    "                ds = TensorDataset(ds_values, ds_labels)\n",
    "\n",
    "                if args.balance:\n",
    "                    # use custom sampler that keeps labels in balance\n",
    "                    labels_unique, labels_count = np.unique(ds_labels.cpu(), return_counts=True) # independent of train-test split (has both classes)\n",
    "                    labels_weights = [\n",
    "                        (1 / labels_count[int(l)])\n",
    "                        for _, l in ds\n",
    "                    ]\n",
    "                    edge_sampler = WeightedRandomSampler(labels_weights, len(labels_weights), replacement=True)\n",
    "                    train_dataloader = DataLoader(ds, batch_size=args.batch_size, sampler=edge_sampler)\n",
    "                else:\n",
    "                    train_dataloader = DataLoader(ds, batch_size=args.batch_size)\n",
    "\n",
    "                for i_batch, (x_train, y_train) in enumerate(train_dataloader):\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    y_pred = self.net(x_train)\n",
    "                    loss = loss_fn(y_pred, y_train.unsqueeze(1))\n",
    "                    # TODO calculate acc\n",
    "\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    epoch_loss_sum += loss.item()\n",
    "\n",
    "                epoch_loss = epoch_loss_sum / len(train_dataloader)\n",
    "                losses.append(epoch_loss)\n",
    "                self.writer.add_scalar('epoch loss', epoch_loss, epoch)\n",
    "\n",
    "                if epoch % 10 == 0 or epoch == args.epochs - 1:\n",
    "                    # print characteristics of used subgraph\n",
    "                    n_sampled_nodes = len(sampled_nodes)\n",
    "                    n_labels = len(labels)\n",
    "                    n_labels_0 = labels.count(0)\n",
    "                    self.writer.add_text(\n",
    "                        \"sample\",\n",
    "                        f\"\"\"\n",
    "                            nodes: {n_sampled_nodes} / {self.graph.n_nodes}\n",
    "                            edges: {n_labels - n_labels_0} / {self.n_labels - self.n_labels_0}\n",
    "                            non-edges: {n_labels_0} / {self.n_labels_0}\n",
    "                        \"\"\",\n",
    "                        epoch\n",
    "                    )\n",
    "                    # evaluate on whole graph\n",
    "                    self.net.eval()\n",
    "                    out = self.net(self.ds_values.to(device))\n",
    "                    raw_pred = torch.sigmoid(out)\n",
    "                    pred = [el.squeeze().tolist() for el in raw_pred]\n",
    "                    self.net.train()\n",
    "\n",
    "                    # save confusion matrix\n",
    "                    bcm = BinaryConfusionMatrix(validate_args=True).to(device)\n",
    "                    conf = bcm(torch.tensor(pred).to(device), self.ds_labels)\n",
    "                    act = np.sum([\n",
    "                        1\n",
    "                        for i, _ in enumerate(self.graph.node_index_pairs)\n",
    "                        if pred[i] > 0.5\n",
    "                    ])\n",
    "                    self.writer.add_text(\n",
    "                        \"confusion\",\n",
    "                        f\"\"\"\n",
    "                            actual edges: {act}\n",
    "                            non-edge | right: {conf[0][0]} / wrong: {conf[0][1]} / all: {self.n_labels_0}\n",
    "                            edge | right: {conf[1][1]} / wrong: {conf[1][0]} / all: {self.n_labels - self.n_labels_0}\n",
    "                        \"\"\",\n",
    "                        epoch\n",
    "                    )\n",
    "                    self.writer.add_scalars('confusion', {\n",
    "                        'false positive edge': conf[0][1] / self.n_labels_0,\n",
    "                        'false negative edge': conf[1][0] / (self.n_labels - self.n_labels_0),\n",
    "                    }, epoch)\n",
    "\n",
    "                    # save figure of reconstruction\n",
    "                    f = self.__print_graph(pred, subgraph=sampled_nodes)\n",
    "                    self.writer.add_figure('predicted graph', f, epoch)\n",
    "\n",
    "\n",
    "                # update progress\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix_str(f\"last epoch loss: {epoch_loss:>6f}\")\n",
    "\n",
    "        if print_losses:\n",
    "            plt.plot(np.array(losses))\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "    def test(self):\n",
    "        self.net.eval()\n",
    "        all_pred_label = []\n",
    "        all_label = []\n",
    "        with torch.no_grad():\n",
    "            test_dataloader = DataLoader(self.dataset, batch_size=args.batch_size)\n",
    "            for i_batch, (x_test, y_test) in enumerate(test_dataloader):\n",
    "                y_pred = self.net(x_test)\n",
    "                pred = torch.sigmoid(y_pred)\n",
    "                pred_label = torch.round(pred)\n",
    "                all_pred_label.append(pred_label.cpu().numpy())\n",
    "                all_label.append(y_test.cpu().numpy())\n",
    "\n",
    "        all_pred_label = sum([el.squeeze().tolist() for el in all_pred_label], [])\n",
    "        all_label = sum([el.squeeze().tolist() for el in all_label], [])\n",
    "\n",
    "        #confusion_matrix(all_label, all_pred_label)\n",
    "        print(classification_report(all_label, all_pred_label))\n",
    "\n",
    "\n",
    "    def evaluate(self, print_report: bool = True, print_graph: bool = True):\n",
    "        self.net.eval()\n",
    "        with torch.no_grad():\n",
    "            out = self.net(self.ds_values.to(device))\n",
    "            pred = torch.sigmoid(out)\n",
    "            pred_label = torch.round(pred)\n",
    "\n",
    "            if print_report:\n",
    "                #? how many wrongly predicted true/false\n",
    "                print(classification_report(\n",
    "                    self.ds_labels.cpu().numpy(),\n",
    "                    pred_label.cpu(),\n",
    "                    labels=[0, 1]\n",
    "                ))\n",
    "\n",
    "            _fig = None\n",
    "            if print_graph:\n",
    "                _pred = [el.squeeze().tolist() for el in pred]\n",
    "                _fig = self.__print_graph(_pred)\n",
    "\n",
    "            return out, pred, pred_label, _fig\n",
    "\n",
    "\n",
    "    def __print_graph(self, pred: List[float], subgraph = None, save_fig: bool = False):\n",
    "        fig, ax = plt.subplots(1, 2)\n",
    "        node_size = 2000 / args.graph_size\n",
    "\n",
    "        nodes_dict = list_to_dict(self.graph.nodes)\n",
    "\n",
    "        # generate embedding graph\n",
    "        embed_graph = nx.Graph()\n",
    "        embed_graph.add_nodes_from(range(self.graph.n_nodes))\n",
    "        sources, targets = self.graph.adjacency_matrix.nonzero()\n",
    "        edges = zip(sources.tolist(), targets.tolist())\n",
    "        embed_graph.add_edges_from(edges)\n",
    "\n",
    "        # color subgraph nodes\n",
    "        node_colors = ['blue'] * self.graph.n_nodes\n",
    "        if subgraph is not None:\n",
    "            for n in subgraph:\n",
    "                node_colors[n] = 'green'\n",
    "\n",
    "        # print embed graph\n",
    "        ax[0].set_axis_off()\n",
    "        ax[0].set_aspect('equal')\n",
    "        ax[0].set_title(\"original graph\")\n",
    "        nx.draw_networkx(embed_graph, pos=nodes_dict, ax=ax[0], node_size=node_size, with_labels=False, labels={}, node_color=node_colors)\n",
    "\n",
    "        # generate predict graph\n",
    "        colors_filtered = np.array([\n",
    "            pred[i]\n",
    "            for i, _ in enumerate(self.graph.node_index_pairs)\n",
    "            if pred[i] > 0.5\n",
    "        ])\n",
    "        colormap = sns.color_palette(\"flare\", as_cmap=True)\n",
    "        pred_graph = nx.Graph()\n",
    "        pred_graph.add_nodes_from(range(self.graph.n_nodes))\n",
    "        pred_graph.add_edges_from([\n",
    "            pair\n",
    "            for i, pair in enumerate(self.graph.node_index_pairs)\n",
    "            if pred[i] > 0.5\n",
    "        ])\n",
    "\n",
    "        # print predicted graph\n",
    "        ax[1].set_axis_off()\n",
    "        ax[1].set_aspect('equal')\n",
    "        ax[1].set_title(\"reconstructed graph\")\n",
    "        nx.draw_networkx(pred_graph, pos=nodes_dict, ax=ax[1], node_size=node_size, with_labels=False, labels={}, edge_color=colors_filtered, edge_cmap=colormap)\n",
    "\n",
    "        # add color bar for predictions\n",
    "        cax = fig.add_axes([ax[1].get_position().x1 + 0.01, ax[1].get_position().y0, 0.02, ax[1].get_position().height])\n",
    "        fig.colorbar(mpl.cm.ScalarMappable(cmap=colormap), cax=cax, label=\"confidence\")\n",
    "\n",
    "        if save_fig:\n",
    "            plt.savefig('./filename.png', dpi=300)\n",
    "        return fig"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "bfs_args = Args()\n",
    "bfs_args.subsample = \"bfs\"\n",
    "bfs_args.subsample_size = 100\n",
    "\n",
    "bfsl_args = Args()\n",
    "bfsl_args.subsample = \"bfs\"\n",
    "bfsl_args.subsample_size = 250\n",
    "\n",
    "walk_args = Args()\n",
    "walk_args.subsample = \"random_walk\"\n",
    "walk_args.subsample_size = 100\n",
    "\n",
    "walkl_args = Args()\n",
    "walkl_args.subsample = \"random_walk\"\n",
    "walkl_args.subsample_size = 250\n",
    "\n",
    "degree_args = Args()\n",
    "degree_args.subsample = \"node_degree\"\n",
    "degree_args.subsample_size = 100\n",
    "\n",
    "degreel_args = Args()\n",
    "degreel_args.subsample = \"node_degree\"\n",
    "degreel_args.subsample_size = 250\n",
    "\n",
    "\n",
    "_args = [\n",
    "    bfs_args,\n",
    "    bfsl_args,\n",
    "    walk_args,\n",
    "    walkl_args,\n",
    "    degree_args,\n",
    "    degreel_args,\n",
    "]\n",
    "_rep = 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "generating random-uniform nodes on disc:   0%|          | 0/800 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0867ba2565dd42ba86d5b32d9b3a8348"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "training model...:   0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c6995ea942a6487b96a15a037bb09fa7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluator = None\n",
    "graph_builder = None\n",
    "\n",
    "for a in _args:\n",
    "    args = a\n",
    "    for _ in range(_rep):\n",
    "        # build and run evaluator\n",
    "        graph_builder = RandomGeometricGraphBuilder()\n",
    "        graph = Graph(\n",
    "            graph_builder.nodes,\n",
    "            graph_builder.adjacency_matrix,\n",
    "        )\n",
    "        evaluator = EmbeddingEvaluator(graph)\n",
    "        evaluator.train(\n",
    "            loss_fn=nn.BCEWithLogitsLoss(),\n",
    "            optimizer=torch.optim.Adam(evaluator.net.parameters(), lr=1e-3)\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluator.test()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# evaluate embedding\n",
    "_, eval_pred, eval_pred_label, figure = evaluator.evaluate()\n",
    "figure.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print edge distance to prediction\n",
    "\n",
    "# generate 10x edges per distance\n",
    "dist_edges = [\n",
    "    (d, [\n",
    "        gen_disc_edge(d)\n",
    "        for _ in range(8)\n",
    "    ])\n",
    "    for d in np.arange(0, 1, 0.001)\n",
    "]\n",
    "\n",
    "xs = []\n",
    "ys_mean = []\n",
    "ys_std = []\n",
    "\n",
    "evaluator.net.eval()\n",
    "with torch.no_grad():\n",
    "    for d, edges in dist_edges:\n",
    "        out = evaluator.net(torch.FloatTensor(edges).to(device))\n",
    "        pred = torch.sigmoid(out)\n",
    "        pred = [el.squeeze().tolist() for el in pred]\n",
    "        xs.append(d)\n",
    "        ys_mean.append(np.mean(pred))\n",
    "        ys_std.append(np.std(pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.scatter(xs, ys_mean)\n",
    "plt.errorbar(xs, ys_mean, xerr=ys_std, xlolims=[std > 0.01 for std in ys_std], linestyle=\"None\")\n",
    "plt.axvline(x=args.rg_radius, color='green')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.scatter(xs, ys_mean)\n",
    "#plt.errorbar(xs, ys_mean, xerr=ys_std, xlolims=[std > 0.01 for std in ys_std], linestyle=\"None\")\n",
    "plt.axvline(x=args.rg_radius, color='green')\n",
    "\n",
    "plt.xlim([0.12, 0.25])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate(self, print_report: bool = True, print_graph: bool = True, th=0.5):\n",
    "    self.net.eval()\n",
    "    with torch.no_grad():\n",
    "        out = self.net(self.ds_values.to(device))\n",
    "        pred = torch.sigmoid(out)\n",
    "        pred_label = torch.round(pred)\n",
    "\n",
    "        if print_report:\n",
    "            #? how many wrongly predicted true/false\n",
    "            print(classification_report(\n",
    "                self.ds_labels.cpu().numpy(),\n",
    "                pred_label.cpu(),\n",
    "                labels=[0, 1]\n",
    "            ))\n",
    "\n",
    "        if print_graph:\n",
    "            _pred = [el.squeeze().tolist() for el in pred]\n",
    "            __print_graph(self, _pred, th=th)\n",
    "\n",
    "        return out, pred, pred_label\n",
    "\n",
    "\n",
    "def __print_graph(self, pred: List[float], th=0.5):\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    nodes_dict = list_to_dict(self.nodes)\n",
    "\n",
    "    # generate embedding graph\n",
    "    embed_graph = nx.Graph()\n",
    "    embed_graph.add_nodes_from(range(self.n_nodes))\n",
    "    embed_graph.add_edges_from(self.edges)\n",
    "\n",
    "    # print embed graph\n",
    "    ax[0].set_axis_off()\n",
    "    ax[0].set_aspect('equal')\n",
    "    ax[0].set_title(\"original graph\")\n",
    "    nx.draw_networkx(embed_graph, pos=nodes_dict, ax=ax[0], node_size=5, with_labels=False, labels={})\n",
    "\n",
    "    # generate predict graph\n",
    "    colors_filtered = np.array([\n",
    "        pred[i]\n",
    "        for i, _ in enumerate(self.node_index_pairs)\n",
    "        if pred[i] > th\n",
    "    ])\n",
    "    colormap = sns.color_palette(\"flare\", as_cmap=True)\n",
    "    pred_graph = nx.Graph()\n",
    "    pred_graph.add_nodes_from(range(self.n_nodes))\n",
    "    pred_graph.add_edges_from([\n",
    "        pair\n",
    "        for i, pair in enumerate(self.node_index_pairs)\n",
    "        if pred[i] > th\n",
    "    ])\n",
    "\n",
    "    # print predicted graph\n",
    "    ax[1].set_axis_off()\n",
    "    ax[1].set_aspect('equal')\n",
    "    ax[1].set_title(\"reconstructed graph\")\n",
    "    nx.draw_networkx(pred_graph, pos=nodes_dict, ax=ax[1], node_size=5, with_labels=False, labels={}, edge_color=colors_filtered, edge_cmap=colormap)\n",
    "\n",
    "    # add color bar for predictions\n",
    "    cax = fig.add_axes([ax[1].get_position().x1 + 0.01, ax[1].get_position().y0, 0.02, ax[1].get_position().height])\n",
    "    fig.colorbar(mpl.cm.ScalarMappable(cmap=colormap), cax=cax, label=\"confidence\")\n",
    "\n",
    "    plt.savefig('./filename.png', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "evaluate(evaluator, th=0.93)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
