{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.getcwd().endswith(\"notebooks\"):\n",
    "    os.chdir(\"..\")\n",
    "    print(\"using project root as working dir\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import List, Tuple\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "@dataclass\n",
    "class Args:\n",
    "    random_seed = None\n",
    "    # torch\n",
    "    batch_size = 10\n",
    "    epochs = 100\n",
    "    layers = 10\n",
    "    layer_size = 16\n",
    "    train_size = 0.8\n",
    "    wandb = False\n",
    "    # graph\n",
    "    graph_size = 800\n",
    "    graph_shape = 'disc'\n",
    "    rg_radius = 0.05\n",
    "    subsample = \"bfs\"\n",
    "    subsample_size = 100\n",
    "    balance = False\n",
    "\n",
    "    def print(self):\n",
    "        return f\"\"\"\n",
    "            random_seed = {self.random_seed}\n",
    "            # torch\n",
    "            batch_size = {self.batch_size}\n",
    "            epochs = {self.epochs}\n",
    "            layers = {self.layers}\n",
    "            layer_size = {self.layer_size}\n",
    "            train_size = {self.train_size}\n",
    "            wandb = {self.wandb}\n",
    "            # graph\n",
    "            graph_size = {self.graph_size}\n",
    "            graph_shape = {self.graph_shape}\n",
    "            rg_radius = {self.rg_radius}\n",
    "            subsample = {self.subsample}\n",
    "            subsample_size = {self.subsample_size}\n",
    "            balance = {self.balance}\n",
    "        \"\"\"\n",
    "\n",
    "args = Args()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, WeightedRandomSampler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"using {device} device\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [],
   "source": [
    "NodePosition = Tuple[float, float]\n",
    "NodePositions = List[NodePosition]\n",
    "NodeIndexPairs = List[Tuple[int, int]]\n",
    "\n",
    "def gen_nodes(size: int, shape: str = \"disc\") -> NodePositions:\n",
    "    if shape == 'disc':\n",
    "        return __gen_nodes_disc(size)\n",
    "    else:\n",
    "        raise f'unsupported node shape: {shape}'\n",
    "\n",
    "\n",
    "def __gen_nodes_disc(amount: int) -> NodePositions:\n",
    "    points = []\n",
    "    with tqdm(total=amount, desc=\"generating random-uniform nodes on disc\") as pbar:\n",
    "        while len(points) < amount:\n",
    "            p = (random.uniform(0, 1), random.uniform(0, 1))\n",
    "            d = (p[0] - 0.5, p[1] - 0.5)\n",
    "            if math.sqrt(d[0] * d[0] + d[1] * d[1]) > 0.5:\n",
    "                continue\n",
    "            points.append(p)\n",
    "            pbar.update(1)\n",
    "    return points\n",
    "\n",
    "# generates an edge with a specified distance on a unit disc\n",
    "# the distance has to be in (0, 1).\n",
    "def gen_disc_edge(d: float) -> [float, float, float, float]:\n",
    "    # loop with p in case p is badly chosen\n",
    "    while True:\n",
    "        px, py = random.uniform(0, 1), random.uniform(0, 1)\n",
    "        v = np.random.random(2) # random direction\n",
    "        vd = (v / np.linalg.norm(v)) * d\n",
    "        [qx, qy] = [px, py] + vd\n",
    "        if math.dist([px, py], [0.5, 0.5]) <= 0.5 and math.dist([qx, qy], [0.5, 0.5]) <= 0.5:\n",
    "            return [px, py, qx, qy]\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/a/36460020/10619052\n",
    "def list_to_dict(items: list) -> dict:\n",
    "    return {v: k for v, k in enumerate(items)}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [],
   "source": [
    "# Define graph builder\n",
    "class RandomGeometricGraphBuilder:\n",
    "    def __init__(self):\n",
    "        # generate graph\n",
    "        self.nodes = gen_nodes(args.graph_size, args.graph_shape)\n",
    "        self.n_nodes = len(self.nodes)\n",
    "        self.graph = nx.random_geometric_graph(\n",
    "            self.n_nodes,\n",
    "            args.rg_radius,\n",
    "            pos=list_to_dict(self.nodes)\n",
    "        )\n",
    "        self.adjacency_matrix = nx.adjacency_matrix(self.graph)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [],
   "source": [
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(4, args.layer_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(args.layer_size, args.layer_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(args.layer_size, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear_relu_stack(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [],
   "source": [
    "# Graph helper class\n",
    "class Graph:\n",
    "    def __init__(self, nodes: NodePositions, adjacency_matrix):\n",
    "        self.nodes = nodes\n",
    "        self.adjacency_matrix = adjacency_matrix\n",
    "        # general pre-calculations\n",
    "        self.n_nodes = len(nodes)\n",
    "        self.node_index_pairs = list(itertools.combinations(range(self.n_nodes), 2))\n",
    "        self.node_degrees = self.adjacency_matrix.sum(axis=0)\n",
    "        # 'random_walk' pre-calculations\n",
    "        self.walk_weights = [\n",
    "            l.todense()[0] if (l := self.node_degrees[i] * self.adjacency_matrix.getrow(i)).sum() > 0 else [1]*self.n_nodes\n",
    "            for i in range(self.n_nodes)\n",
    "        ]\n",
    "\n",
    "    def subgraph(self, alg: str, size: int, replacement: bool = False) -> List[int]:\n",
    "        if alg == \"node_degree\":\n",
    "            return self.node_degree_subgraph(size, replacement)\n",
    "        elif alg == \"random_walk\":\n",
    "            return self.random_walk_subgraph(size, replacement)\n",
    "        elif alg == \"bfs\":\n",
    "            return self.bfs_subgraph(size)\n",
    "\n",
    "\n",
    "    def node_degree_subgraph(self, size: int, replacement: bool = False):\n",
    "        return list(WeightedRandomSampler(self.node_degrees, size, replacement=replacement))\n",
    "\n",
    "\n",
    "    def random_walk_subgraph(self, size: int, replacement: bool = False):\n",
    "        def walk(start: int, n: int):\n",
    "            for _ in range(n):\n",
    "                yield start\n",
    "                start = random.choices(\n",
    "                    range(self.n_nodes),\n",
    "                    weights=self.walk_weights[start]\n",
    "                )[0]\n",
    "        return list(walk(\n",
    "            random.choices(\n",
    "                range(self.n_nodes),\n",
    "                weights=self.node_degrees\n",
    "            )[0],\n",
    "            size\n",
    "        ))\n",
    "\n",
    "\n",
    "    def bfs_subgraph(self, size: int):\n",
    "        def bfs(start: int, n: int):\n",
    "            visit = [start]\n",
    "            visited = []\n",
    "            for _ in range(n):\n",
    "                if len(visit) == 0:\n",
    "                    visit.append(\n",
    "                        random.choice(range(self.n_nodes)))\n",
    "                    print(\"random jump\")\n",
    "                curr = visit.pop(0)\n",
    "                visited.append(curr)\n",
    "                yield curr\n",
    "                visit.extend([\n",
    "                    n\n",
    "                    for n in range(self.n_nodes)\n",
    "                    if self.adjacency_matrix[curr, n] == 1 and n not in visited\n",
    "                ])\n",
    "        return list(bfs(\n",
    "            random.choice(\n",
    "                range(self.n_nodes)\n",
    "            ),\n",
    "            size\n",
    "        ))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [
    {
     "data": {
      "text/plain": "generating random-uniform nodes on disc:   0%|          | 0/800 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "234d30a92d9343129c1deb777ecff599"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "[37, 1, 152, 222, 394, 415, 462, 489, 545, 561]"
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder = RandomGeometricGraphBuilder()\n",
    "graph = Graph(\n",
    "    graph_builder.nodes,\n",
    "    graph_builder.adjacency_matrix,\n",
    ")\n",
    "graph.bfs_subgraph(10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [],
   "source": [
    "# Define evaluator\n",
    "class EmbeddingEvaluator:\n",
    "    def __init__(self, graph: Graph):\n",
    "        self.graph = graph\n",
    "        # complete dataset\n",
    "        ds_values = [ e.flatten().tolist() for e in np.array(self.graph.nodes)[self.graph.node_index_pairs]]\n",
    "        ds_labels = [ int(self.graph.adjacency_matrix[s]) for s in self.graph.node_index_pairs ]\n",
    "        self.ds_values = torch.FloatTensor(ds_values).to(device)\n",
    "        self.ds_labels = torch.FloatTensor(ds_labels).to(device)\n",
    "        self.dataset = TensorDataset(self.ds_values, self.ds_labels)\n",
    "        self.dataloader = DataLoader(self.dataset, batch_size=args.batch_size, shuffle=True)\n",
    "        # generate net\n",
    "        self.net = NeuralNetwork().to(device)\n",
    "        # tensorboard\n",
    "        self.writer = SummaryWriter()\n",
    "\n",
    "    def train(self, loss_fn, optimizer, print_losses: bool = True):\n",
    "        losses = []\n",
    "        self.writer.add_text(\"args\", args.print())\n",
    "\n",
    "        self.net.train()\n",
    "        with tqdm(total=args.epochs, desc=\"training model...\") as pbar:\n",
    "            for epoch in range(args.epochs):\n",
    "                pbar.set_description(f\"epoch {epoch + 1}\")\n",
    "                epoch_loss_sum = 0\n",
    "\n",
    "                # sample subgraph (by node degree) and generate dataset\n",
    "                sampled_nodes = self.graph.subgraph(args.subsample, args.subsample_size)\n",
    "                #? bft search\n",
    "                #? forest fire\n",
    "\n",
    "                sampled_node_pairs = list(itertools.combinations(sampled_nodes, 2))\n",
    "                values = [ e.flatten().tolist() for e in np.array(self.graph.nodes)[sampled_node_pairs]]\n",
    "                labels = [ int(self.graph.adjacency_matrix[s]) for s in sampled_node_pairs ]\n",
    "\n",
    "                ds_values = torch.FloatTensor(values).to(device)\n",
    "                ds_labels = torch.FloatTensor(labels).to(device)\n",
    "                ds = TensorDataset(ds_values, ds_labels)\n",
    "\n",
    "                if args.balance:\n",
    "                    # use custom sampler that keeps labels in balance\n",
    "                    labels_unique, labels_count = np.unique(ds_labels.cpu(), return_counts=True) # independent of train-test split (has both classes)\n",
    "                    labels_weights = [\n",
    "                        (1 / labels_count[int(l)])\n",
    "                        for _, l in ds\n",
    "                    ]\n",
    "                    edge_sampler = WeightedRandomSampler(labels_weights, len(labels_weights), replacement=True)\n",
    "                    train_dataloader = DataLoader(ds, batch_size=args.batch_size, sampler=edge_sampler)\n",
    "                else:\n",
    "                    train_dataloader = DataLoader(ds, batch_size=args.batch_size)\n",
    "\n",
    "                for i_batch, (x_train, y_train) in enumerate(train_dataloader):\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    y_pred = self.net(x_train)\n",
    "                    loss = loss_fn(y_pred, y_train.unsqueeze(1))\n",
    "                    # TODO calculate acc\n",
    "\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    epoch_loss_sum += loss.item()\n",
    "\n",
    "                epoch_loss = epoch_loss_sum / len(train_dataloader)\n",
    "                losses.append(epoch_loss)\n",
    "                self.writer.add_scalar('epoch loss', epoch_loss, epoch)\n",
    "\n",
    "                if epoch % 10 == 0 or epoch == args.epochs - 1:\n",
    "                    self.net.eval()\n",
    "                    out = self.net(self.ds_values.to(device))\n",
    "                    pred = torch.sigmoid(out)\n",
    "                    f = self.__print_graph([el.squeeze().tolist() for el in pred], subgraph=sampled_nodes)\n",
    "                    self.writer.add_figure('predicted graph', f, epoch)\n",
    "\n",
    "                    self.net.train()\n",
    "\n",
    "\n",
    "                # update progress\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix_str(f\"last epoch loss: {epoch_loss:>6f}\")\n",
    "\n",
    "        if print_losses:\n",
    "            plt.plot(np.array(losses))\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "    def test(self):\n",
    "        self.net.eval()\n",
    "        all_pred_label = []\n",
    "        all_label = []\n",
    "        with torch.no_grad():\n",
    "            test_dataloader = DataLoader(self.dataset, batch_size=args.batch_size)\n",
    "            for i_batch, (x_test, y_test) in enumerate(test_dataloader):\n",
    "                y_pred = self.net(x_test)\n",
    "                pred = torch.sigmoid(y_pred)\n",
    "                pred_label = torch.round(pred)\n",
    "                all_pred_label.append(pred_label.cpu().numpy())\n",
    "                all_label.append(y_test.cpu().numpy())\n",
    "\n",
    "        all_pred_label = sum([el.squeeze().tolist() for el in all_pred_label], [])\n",
    "        all_label = sum([el.squeeze().tolist() for el in all_label], [])\n",
    "\n",
    "        #confusion_matrix(all_label, all_pred_label)\n",
    "        print(classification_report(all_label, all_pred_label))\n",
    "\n",
    "\n",
    "    def evaluate(self, print_report: bool = True, print_graph: bool = True):\n",
    "        self.net.eval()\n",
    "        with torch.no_grad():\n",
    "            out = self.net(self.ds_values.to(device))\n",
    "            pred = torch.sigmoid(out)\n",
    "            pred_label = torch.round(pred)\n",
    "\n",
    "            if print_report:\n",
    "                #? how many wrongly predicted true/false\n",
    "                print(classification_report(\n",
    "                    self.ds_labels.cpu().numpy(),\n",
    "                    pred_label.cpu(),\n",
    "                    labels=[0, 1]\n",
    "                ))\n",
    "\n",
    "            _fig = None\n",
    "            if print_graph:\n",
    "                _pred = [el.squeeze().tolist() for el in pred]\n",
    "                _fig = self.__print_graph(_pred)\n",
    "\n",
    "            return out, pred, pred_label, _fig\n",
    "\n",
    "\n",
    "    def __print_graph(self, pred: List[float], subgraph = None, save_fig: bool = False):\n",
    "        fig, ax = plt.subplots(1, 2)\n",
    "        node_size = 2000 / args.graph_size\n",
    "\n",
    "        nodes_dict = list_to_dict(self.graph.nodes)\n",
    "\n",
    "        # generate embedding graph\n",
    "        embed_graph = nx.Graph()\n",
    "        embed_graph.add_nodes_from(range(self.graph.n_nodes))\n",
    "        sources, targets = self.graph.adjacency_matrix.nonzero()\n",
    "        edges = zip(sources.tolist(), targets.tolist())\n",
    "        embed_graph.add_edges_from(edges)\n",
    "\n",
    "        # color subgraph nodes\n",
    "        node_colors = ['blue'] * self.graph.n_nodes\n",
    "        if subgraph is not None:\n",
    "            for n in subgraph:\n",
    "                node_colors[n] = 'green'\n",
    "\n",
    "        # print embed graph\n",
    "        ax[0].set_axis_off()\n",
    "        ax[0].set_aspect('equal')\n",
    "        ax[0].set_title(\"original graph\")\n",
    "        nx.draw_networkx(embed_graph, pos=nodes_dict, ax=ax[0], node_size=node_size, with_labels=False, labels={}, node_color=node_colors)\n",
    "\n",
    "        # generate predict graph\n",
    "        colors_filtered = np.array([\n",
    "            pred[i]\n",
    "            for i, _ in enumerate(self.graph.node_index_pairs)\n",
    "            if pred[i] > 0.5\n",
    "        ])\n",
    "        colormap = sns.color_palette(\"flare\", as_cmap=True)\n",
    "        pred_graph = nx.Graph()\n",
    "        pred_graph.add_nodes_from(range(self.graph.n_nodes))\n",
    "        pred_graph.add_edges_from([\n",
    "            pair\n",
    "            for i, pair in enumerate(self.graph.node_index_pairs)\n",
    "            if pred[i] > 0.5\n",
    "        ])\n",
    "\n",
    "        # print predicted graph\n",
    "        ax[1].set_axis_off()\n",
    "        ax[1].set_aspect('equal')\n",
    "        ax[1].set_title(\"reconstructed graph\")\n",
    "        nx.draw_networkx(pred_graph, pos=nodes_dict, ax=ax[1], node_size=node_size, with_labels=False, labels={}, edge_color=colors_filtered, edge_cmap=colormap)\n",
    "\n",
    "        # add color bar for predictions\n",
    "        cax = fig.add_axes([ax[1].get_position().x1 + 0.01, ax[1].get_position().y0, 0.02, ax[1].get_position().height])\n",
    "        fig.colorbar(mpl.cm.ScalarMappable(cmap=colormap), cax=cax, label=\"confidence\")\n",
    "\n",
    "        if save_fig:\n",
    "            plt.savefig('./filename.png', dpi=300)\n",
    "        return fig"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [
    {
     "data": {
      "text/plain": "generating random-uniform nodes on disc:   0%|          | 0/800 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aab667d4dd0b46f780a60c513c54862d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "training model...:   0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d2fe329d0eed4e81a3902f0e34362762"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[162], line 12\u001B[0m\n\u001B[1;32m      7\u001B[0m graph \u001B[38;5;241m=\u001B[39m Graph(\n\u001B[1;32m      8\u001B[0m     graph_builder\u001B[38;5;241m.\u001B[39mnodes,\n\u001B[1;32m      9\u001B[0m     graph_builder\u001B[38;5;241m.\u001B[39madjacency_matrix,\n\u001B[1;32m     10\u001B[0m )\n\u001B[1;32m     11\u001B[0m evaluator \u001B[38;5;241m=\u001B[39m EmbeddingEvaluator(graph)\n\u001B[0;32m---> 12\u001B[0m \u001B[43mevaluator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m    \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mBCEWithLogitsLoss\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptim\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mAdam\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnet\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1e-3\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[161], line 27\u001B[0m, in \u001B[0;36mEmbeddingEvaluator.train\u001B[0;34m(self, loss_fn, optimizer, print_losses)\u001B[0m\n\u001B[1;32m     24\u001B[0m epoch_loss_sum \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;66;03m# sample subgraph (by node degree) and generate dataset\u001B[39;00m\n\u001B[0;32m---> 27\u001B[0m sampled_nodes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgraph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msubgraph\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msubsample\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msubsample_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;66;03m#? bft search\u001B[39;00m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;66;03m#? forest fire\u001B[39;00m\n\u001B[1;32m     31\u001B[0m sampled_node_pairs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(itertools\u001B[38;5;241m.\u001B[39mcombinations(sampled_nodes, \u001B[38;5;241m2\u001B[39m))\n",
      "Cell \u001B[0;32mIn[159], line 22\u001B[0m, in \u001B[0;36mGraph.subgraph\u001B[0;34m(self, alg, size, replacement)\u001B[0m\n\u001B[1;32m     20\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrandom_walk_subgraph(size, replacement)\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m alg \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbfs\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m---> 22\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbfs_subgraph\u001B[49m\u001B[43m(\u001B[49m\u001B[43msize\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[159], line 63\u001B[0m, in \u001B[0;36mGraph.bfs_subgraph\u001B[0;34m(self, size)\u001B[0m\n\u001B[1;32m     57\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m start\n\u001B[1;32m     58\u001B[0m         visit\u001B[38;5;241m.\u001B[39mextend([\n\u001B[1;32m     59\u001B[0m             n\n\u001B[1;32m     60\u001B[0m             \u001B[38;5;28;01mfor\u001B[39;00m n \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_nodes)\n\u001B[1;32m     61\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madjacency_matrix[curr, n] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m n \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m visited\n\u001B[1;32m     62\u001B[0m         ])\n\u001B[0;32m---> 63\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mbfs\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     64\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrandom\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchoice\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     65\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mrange\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_nodes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     67\u001B[0m \u001B[43m    \u001B[49m\u001B[43msize\u001B[49m\n\u001B[1;32m     68\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[159], line 58\u001B[0m, in \u001B[0;36mGraph.bfs_subgraph.<locals>.bfs\u001B[0;34m(start, n)\u001B[0m\n\u001B[1;32m     56\u001B[0m visited\u001B[38;5;241m.\u001B[39mappend(curr)\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01myield\u001B[39;00m start\n\u001B[0;32m---> 58\u001B[0m visit\u001B[38;5;241m.\u001B[39mextend([\n\u001B[1;32m     59\u001B[0m     n\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m n \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_nodes)\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madjacency_matrix[curr, n] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m n \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m visited\n\u001B[1;32m     62\u001B[0m ])\n",
      "Cell \u001B[0;32mIn[159], line 61\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     56\u001B[0m visited\u001B[38;5;241m.\u001B[39mappend(curr)\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01myield\u001B[39;00m start\n\u001B[1;32m     58\u001B[0m visit\u001B[38;5;241m.\u001B[39mextend([\n\u001B[1;32m     59\u001B[0m     n\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m n \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_nodes)\n\u001B[0;32m---> 61\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madjacency_matrix\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcurr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m n \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m visited\n\u001B[1;32m     62\u001B[0m ])\n",
      "File \u001B[0;32m~/Projects/embedding-eval-framework/venv/lib/python3.8/site-packages/scipy/sparse/_index.py:52\u001B[0m, in \u001B[0;36mIndexMixin.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(row, INT_TYPES):\n\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(col, INT_TYPES):\n\u001B[0;32m---> 52\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_intXint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrow\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcol\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     53\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(col, \u001B[38;5;28mslice\u001B[39m):\n\u001B[1;32m     54\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_raise_on_1d_array_slice()\n",
      "File \u001B[0;32m~/Projects/embedding-eval-framework/venv/lib/python3.8/site-packages/scipy/sparse/_compressed.py:657\u001B[0m, in \u001B[0;36m_cs_matrix._get_intXint\u001B[0;34m(self, row, col)\u001B[0m\n\u001B[1;32m    655\u001B[0m M, N \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_swap(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshape)\n\u001B[1;32m    656\u001B[0m major, minor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_swap((row, col))\n\u001B[0;32m--> 657\u001B[0m indptr, indices, data \u001B[38;5;241m=\u001B[39m \u001B[43mget_csr_submatrix\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    658\u001B[0m \u001B[43m    \u001B[49m\u001B[43mM\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mN\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindptr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindices\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    659\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmajor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmajor\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mminor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mminor\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    660\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m data\u001B[38;5;241m.\u001B[39msum(dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdtype)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "evaluator = None\n",
    "graph_builder = None\n",
    "\n",
    "_args = [\n",
    "    Args(),\n",
    "    Args(),\n",
    "    Args(),\n",
    "]\n",
    "\n",
    "for a in _args:\n",
    "    args = a\n",
    "    for _ in range(4):\n",
    "        # build and run evaluator\n",
    "        graph_builder = RandomGeometricGraphBuilder()\n",
    "        graph = Graph(\n",
    "            graph_builder.nodes,\n",
    "            graph_builder.adjacency_matrix,\n",
    "        )\n",
    "        evaluator = EmbeddingEvaluator(graph)\n",
    "        evaluator.train(\n",
    "            loss_fn=nn.BCEWithLogitsLoss(),\n",
    "            optimizer=torch.optim.Adam(evaluator.net.parameters(), lr=1e-3)\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluator.test()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# evaluate embedding\n",
    "_, eval_pred, eval_pred_label, figure = evaluator.evaluate()\n",
    "figure.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print edge distance to prediction\n",
    "\n",
    "# generate 10x edges per distance\n",
    "dist_edges = [\n",
    "    (d, [\n",
    "        gen_disc_edge(d)\n",
    "        for _ in range(8)\n",
    "    ])\n",
    "    for d in np.arange(0, 1, 0.001)\n",
    "]\n",
    "\n",
    "xs = []\n",
    "ys_mean = []\n",
    "ys_std = []\n",
    "\n",
    "evaluator.net.eval()\n",
    "with torch.no_grad():\n",
    "    for d, edges in dist_edges:\n",
    "        out = evaluator.net(torch.FloatTensor(edges).to(device))\n",
    "        pred = torch.sigmoid(out)\n",
    "        pred = [el.squeeze().tolist() for el in pred]\n",
    "        xs.append(d)\n",
    "        ys_mean.append(np.mean(pred))\n",
    "        ys_std.append(np.std(pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.scatter(xs, ys_mean)\n",
    "plt.errorbar(xs, ys_mean, xerr=ys_std, xlolims=[std > 0.01 for std in ys_std], linestyle=\"None\")\n",
    "plt.axvline(x=args.rg_radius, color='green')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.scatter(xs, ys_mean)\n",
    "#plt.errorbar(xs, ys_mean, xerr=ys_std, xlolims=[std > 0.01 for std in ys_std], linestyle=\"None\")\n",
    "plt.axvline(x=args.rg_radius, color='green')\n",
    "\n",
    "plt.xlim([0.12, 0.25])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate(self, print_report: bool = True, print_graph: bool = True, th=0.5):\n",
    "    self.net.eval()\n",
    "    with torch.no_grad():\n",
    "        out = self.net(self.ds_values.to(device))\n",
    "        pred = torch.sigmoid(out)\n",
    "        pred_label = torch.round(pred)\n",
    "\n",
    "        if print_report:\n",
    "            #? how many wrongly predicted true/false\n",
    "            print(classification_report(\n",
    "                self.ds_labels.cpu().numpy(),\n",
    "                pred_label.cpu(),\n",
    "                labels=[0, 1]\n",
    "            ))\n",
    "\n",
    "        if print_graph:\n",
    "            _pred = [el.squeeze().tolist() for el in pred]\n",
    "            __print_graph(self, _pred, th=th)\n",
    "\n",
    "        return out, pred, pred_label\n",
    "\n",
    "\n",
    "def __print_graph(self, pred: List[float], th=0.5):\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    nodes_dict = list_to_dict(self.nodes)\n",
    "\n",
    "    # generate embedding graph\n",
    "    embed_graph = nx.Graph()\n",
    "    embed_graph.add_nodes_from(range(self.n_nodes))\n",
    "    embed_graph.add_edges_from(self.edges)\n",
    "\n",
    "    # print embed graph\n",
    "    ax[0].set_axis_off()\n",
    "    ax[0].set_aspect('equal')\n",
    "    ax[0].set_title(\"original graph\")\n",
    "    nx.draw_networkx(embed_graph, pos=nodes_dict, ax=ax[0], node_size=5, with_labels=False, labels={})\n",
    "\n",
    "    # generate predict graph\n",
    "    colors_filtered = np.array([\n",
    "        pred[i]\n",
    "        for i, _ in enumerate(self.node_index_pairs)\n",
    "        if pred[i] > th\n",
    "    ])\n",
    "    colormap = sns.color_palette(\"flare\", as_cmap=True)\n",
    "    pred_graph = nx.Graph()\n",
    "    pred_graph.add_nodes_from(range(self.n_nodes))\n",
    "    pred_graph.add_edges_from([\n",
    "        pair\n",
    "        for i, pair in enumerate(self.node_index_pairs)\n",
    "        if pred[i] > th\n",
    "    ])\n",
    "\n",
    "    # print predicted graph\n",
    "    ax[1].set_axis_off()\n",
    "    ax[1].set_aspect('equal')\n",
    "    ax[1].set_title(\"reconstructed graph\")\n",
    "    nx.draw_networkx(pred_graph, pos=nodes_dict, ax=ax[1], node_size=5, with_labels=False, labels={}, edge_color=colors_filtered, edge_cmap=colormap)\n",
    "\n",
    "    # add color bar for predictions\n",
    "    cax = fig.add_axes([ax[1].get_position().x1 + 0.01, ax[1].get_position().y0, 0.02, ax[1].get_position().height])\n",
    "    fig.colorbar(mpl.cm.ScalarMappable(cmap=colormap), cax=cax, label=\"confidence\")\n",
    "\n",
    "    plt.savefig('./filename.png', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "evaluate(evaluator, th=0.93)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
